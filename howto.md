# Running local instance
0. serve local LLM with ollama ```ollama run llama2```
1. install and activate your environment```bash poetry init```
2. ```poetry install --virtualenvs.in-project```
3. ```poetry shell```
4. ```poetry run python main.py```


